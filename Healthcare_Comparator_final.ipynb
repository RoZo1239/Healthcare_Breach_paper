{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad4f3a-c03d-4734-9846-6b36932e535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, scrolledtext\n",
    "from tkinter import ttk\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from datetime import datetime\n",
    "import re\n",
    "import threading\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import ollama\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# ------------------------------\n",
    "# Helper Functions\n",
    "# ------------------------------\n",
    "\n",
    "def extract_records(doc_path):\n",
    "    doc = Document(doc_path)\n",
    "\n",
    "    full_text = \"\\n\".join(\n",
    "        para.text.strip()\n",
    "        for para in doc.paragraphs\n",
    "        if para.text.strip()\n",
    "    )\n",
    "\n",
    "    full_text = full_text.replace(\"—\", \"-\").replace(\"–\", \"-\")\n",
    "\n",
    "    record_splits = re.split(\n",
    "        r'(?im)(?=^\\s*record\\s+\\d+\\b)',\n",
    "        full_text\n",
    "    )\n",
    "\n",
    "    records = []\n",
    "    for chunk in record_splits:\n",
    "        if re.match(r'(?im)^\\s*record\\s+\\d+\\b', chunk):\n",
    "            records.append(chunk.strip())\n",
    "\n",
    "    return records\n",
    "\n",
    "\n",
    "def extract_sections(record_text):\n",
    "    mitigation = re.findall(r'Mitigation[:\\s-]*(.*?)(?=\\n\\d+\\.|$)', record_text, re.DOTALL | re.IGNORECASE)\n",
    "    prevention = re.findall(r'Prevention[:\\s-]*(.*?)(?=\\n\\d+\\.|$)', record_text, re.DOTALL | re.IGNORECASE)\n",
    "    resources = re.findall(r'(NIST|HIPAA|GDPR|HHS)', record_text, re.IGNORECASE)\n",
    "\n",
    "    return {\n",
    "        \"mitigation\": \"\\n\".join(mitigation).strip(),\n",
    "        \"prevention\": \"\\n\".join(prevention).strip(),\n",
    "        \"resources\": \", \".join(set(resources))\n",
    "    }\n",
    "\n",
    "\n",
    "def get_llm_insight(section, text1, text2):\n",
    "    if not text1 and not text2:\n",
    "        return \"Both documents have no content for this section.\"\n",
    "    elif not text1:\n",
    "        return \"Only Document 2 has content in this section.\"\n",
    "    elif not text2:\n",
    "        return \"Only Document 1 has content in this section.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Compare the following two {section} sections.\n",
    "Explain similarities and differences. Highlight common themes and missing elements.\n",
    "\n",
    "Document 1 {section}:\n",
    "{text1}\n",
    "\n",
    "Document 2 {section}:\n",
    "{text2}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response[\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        return f\"LLM insight unavailable: {e}\"\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# GUI Application\n",
    "# ------------------------------\n",
    "\n",
    "class BreachComparerApp(tk.Tk):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title(\"Healthcare Breach Semantic Comparator with Insights\")\n",
    "        self.geometry(\"1350x820\")\n",
    "\n",
    "        self.doc1_records = []\n",
    "        self.doc2_records = []\n",
    "\n",
    "        self.comparison_results = []\n",
    "        self.overall_averages = {}\n",
    "\n",
    "        self.model = None\n",
    "\n",
    "        self.setup_ui()\n",
    "        threading.Thread(target=self.load_model, daemon=True).start()\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    def semantic_similarity(self, text1, text2):\n",
    "        if not text1 or not text2 or self.model is None:\n",
    "            return 0.0\n",
    "\n",
    "        emb1 = self.model.encode(text1, convert_to_tensor=True)\n",
    "        emb2 = self.model.encode(text2, convert_to_tensor=True)\n",
    "        sim = util.cos_sim(emb1, emb2).item()\n",
    "        return round(sim * 100, 2)\n",
    "\n",
    "    # ---------------- UI ----------------\n",
    "\n",
    "    def setup_ui(self):\n",
    "\n",
    "        self.btn_load1 = tk.Button(self, text=\"Load Document 1\", command=self.load_doc1)\n",
    "        self.btn_load1.grid(row=0, column=0, padx=5, pady=5)\n",
    "\n",
    "        self.doc1_label = tk.Label(self, text=\"No file loaded\")\n",
    "        self.doc1_label.grid(row=0, column=1, sticky='w')\n",
    "\n",
    "        self.btn_load2 = tk.Button(self, text=\"Load Document 2\", command=self.load_doc2)\n",
    "        self.btn_load2.grid(row=1, column=0, padx=5, pady=5)\n",
    "\n",
    "        self.doc2_label = tk.Label(self, text=\"No file loaded\")\n",
    "        self.doc2_label.grid(row=1, column=1, sticky='w')\n",
    "\n",
    "        self.btn_compare = tk.Button(self, text=\"Compare Records\", command=self.start_comparison_thread)\n",
    "        self.btn_compare.grid(row=2, column=0, pady=10)\n",
    "\n",
    "        self.btn_export_excel = tk.Button(self, text=\"Download Excel Report\", command=self.export_excel)\n",
    "        self.btn_export_excel.grid(row=2, column=1, pady=10)\n",
    "\n",
    "        self.btn_export_word = tk.Button(self, text=\"Download Word Report\", command=self.export_word_report)\n",
    "        self.btn_export_word.grid(row=2, column=2, pady=10)\n",
    "\n",
    "        self.progress_label = tk.Label(self, text=\"Ready\")\n",
    "        self.progress_label.grid(row=2, column=3, padx=10)\n",
    "\n",
    "        self.progress_bar = ttk.Progressbar(self, length=300, mode='determinate')\n",
    "        self.progress_bar.grid(row=2, column=4, padx=10)\n",
    "\n",
    "        self.result_text = scrolledtext.ScrolledText(self, width=160, height=18, wrap=tk.WORD)\n",
    "        self.result_text.grid(row=3, column=0, columnspan=5, padx=10, pady=10)\n",
    "\n",
    "        self.tree = ttk.Treeview(\n",
    "            self,\n",
    "            columns=(\"Record\", \"Mitigation\", \"Prevention\", \"Resources\", \"Overall\"),\n",
    "            show=\"headings\"\n",
    "        )\n",
    "\n",
    "        for col in self.tree[\"columns\"]:\n",
    "            self.tree.heading(col, text=col)\n",
    "\n",
    "        self.tree.grid(row=4, column=0, columnspan=5, padx=10, pady=10)\n",
    "\n",
    "        self.overall_table = ttk.Treeview(\n",
    "            self,\n",
    "            columns=(\"Section\", \"Average Similarity\"),\n",
    "            show=\"headings\"\n",
    "        )\n",
    "\n",
    "        self.overall_table.heading(\"Section\", text=\"Section\")\n",
    "        self.overall_table.heading(\"Average Similarity\", text=\"Average Similarity (%)\")\n",
    "\n",
    "        self.overall_table.grid(row=5, column=0, columnspan=5, padx=10, pady=10)\n",
    "\n",
    "    # ---------------- File Load ----------------\n",
    "\n",
    "    def load_doc1(self):\n",
    "        path = filedialog.askopenfilename(filetypes=[(\"Word Documents\", \"*.docx\")])\n",
    "        if path:\n",
    "            self.doc1_records = extract_records(path)\n",
    "            self.doc1_label.config(text=f\"{len(self.doc1_records)} records loaded\")\n",
    "\n",
    "    def load_doc2(self):\n",
    "        path = filedialog.askopenfilename(filetypes=[(\"Word Documents\", \"*.docx\")])\n",
    "        if path:\n",
    "            self.doc2_records = extract_records(path)\n",
    "            self.doc2_label.config(text=f\"{len(self.doc2_records)} records loaded\")\n",
    "\n",
    "    # ---------------- Comparison ----------------\n",
    "\n",
    "    def start_comparison_thread(self):\n",
    "\n",
    "        if not self.doc1_records or not self.doc2_records:\n",
    "            messagebox.showwarning(\"Warning\", \"Please load both documents first.\")\n",
    "            return\n",
    "\n",
    "        self.result_text.delete(1.0, tk.END)\n",
    "        self.tree.delete(*self.tree.get_children())\n",
    "        self.overall_table.delete(*self.overall_table.get_children())\n",
    "        self.comparison_results.clear()\n",
    "\n",
    "        total_records = max(len(self.doc1_records), len(self.doc2_records))\n",
    "\n",
    "        self.progress_bar[\"value\"] = 0\n",
    "        self.progress_bar[\"maximum\"] = total_records\n",
    "        self.progress_label.config(text=f\"Processing 0 of {total_records}\")\n",
    "\n",
    "        self.btn_compare.config(state=\"disabled\")\n",
    "        self.btn_export_excel.config(state=\"disabled\")\n",
    "        self.btn_export_word.config(state=\"disabled\")\n",
    "\n",
    "        threading.Thread(target=self.compare_records, daemon=True).start()\n",
    "\n",
    "    def update_progress(self, current, total):\n",
    "        self.progress_bar[\"value\"] = current\n",
    "        self.progress_label.config(text=f\"Processing {current} of {total}\")\n",
    "\n",
    "        if current == total:\n",
    "            self.progress_label.config(text=\"Processing Complete\")\n",
    "            self.btn_compare.config(state=\"normal\")\n",
    "            self.btn_export_excel.config(state=\"normal\")\n",
    "            self.btn_export_word.config(state=\"normal\")\n",
    "\n",
    "    def compare_records(self):\n",
    "\n",
    "        total_records = max(len(self.doc1_records), len(self.doc2_records))\n",
    "\n",
    "        mitigation_scores = []\n",
    "        prevention_scores = []\n",
    "        resource_scores = []\n",
    "\n",
    "        for i in range(total_records):\n",
    "\n",
    "            rec1 = self.doc1_records[i] if i < len(self.doc1_records) else \"\"\n",
    "            rec2 = self.doc2_records[i] if i < len(self.doc2_records) else \"\"\n",
    "\n",
    "            sec1 = extract_sections(rec1)\n",
    "            sec2 = extract_sections(rec2)\n",
    "\n",
    "            mitigation_sim = self.semantic_similarity(sec1['mitigation'], sec2['mitigation'])\n",
    "            prevention_sim = self.semantic_similarity(sec1['prevention'], sec2['prevention'])\n",
    "            resources_sim = self.semantic_similarity(sec1['resources'], sec2['resources'])\n",
    "\n",
    "            valid = [s for s in [mitigation_sim, prevention_sim, resources_sim] if s > 0]\n",
    "            overall_sim = round(sum(valid)/len(valid), 2) if valid else 0\n",
    "\n",
    "            mitigation_scores.append(mitigation_sim)\n",
    "            prevention_scores.append(prevention_sim)\n",
    "            resource_scores.append(resources_sim)\n",
    "\n",
    "            mitigation_insight = get_llm_insight(\"Mitigation\", sec1['mitigation'], sec2['mitigation'])\n",
    "            prevention_insight = get_llm_insight(\"Prevention\", sec1['prevention'], sec2['prevention'])\n",
    "            resources_insight = get_llm_insight(\"Resources\", sec1['resources'], sec2['resources'])\n",
    "\n",
    "            self.comparison_results.append({\n",
    "                \"record\": i+1,\n",
    "                \"mitigation\": mitigation_sim,\n",
    "                \"prevention\": prevention_sim,\n",
    "                \"resources\": resources_sim,\n",
    "                \"overall\": overall_sim,\n",
    "                \"mitigation_insight\": mitigation_insight,\n",
    "                \"prevention_insight\": prevention_insight,\n",
    "                \"resources_insight\": resources_insight\n",
    "            })\n",
    "\n",
    "            self.tree.insert(\"\", \"end\",\n",
    "                             values=(f\"Record {i+1}\", mitigation_sim,\n",
    "                                     prevention_sim, resources_sim, overall_sim))\n",
    "\n",
    "            self.result_text.insert(tk.END,\n",
    "                f\"=== Record {i+1} ===\\n\"\n",
    "                f\"Mitigation ({mitigation_sim}%):\\n{mitigation_insight}\\n\\n\"\n",
    "                f\"Prevention ({prevention_sim}%):\\n{prevention_insight}\\n\\n\"\n",
    "                f\"Resources ({resources_sim}%):\\n{resources_insight}\\n\\n\"\n",
    "                f\"Overall Similarity: {overall_sim}%\\n\"\n",
    "                + \"=\"*100 + \"\\n\\n\"\n",
    "            )\n",
    "\n",
    "            self.after(0, self.update_progress, i+1, total_records)\n",
    "\n",
    "        avg_mit = round(sum(mitigation_scores)/len(mitigation_scores),2) if mitigation_scores else 0\n",
    "        avg_prev = round(sum(prevention_scores)/len(prevention_scores),2) if prevention_scores else 0\n",
    "        avg_res = round(sum(resource_scores)/len(resource_scores),2) if resource_scores else 0\n",
    "        avg_overall = round((avg_mit+avg_prev+avg_res)/3,2)\n",
    "\n",
    "        self.overall_averages = {\n",
    "            \"Mitigation\": avg_mit,\n",
    "            \"Prevention\": avg_prev,\n",
    "            \"Resources\": avg_res,\n",
    "            \"Overall\": avg_overall\n",
    "        }\n",
    "\n",
    "        for k,v in self.overall_averages.items():\n",
    "            self.overall_table.insert(\"\", \"end\", values=(k, v))\n",
    "\n",
    "    # ---------------- Excel Export ----------------\n",
    "\n",
    "    def export_excel(self):\n",
    "\n",
    "        if not self.comparison_results:\n",
    "            messagebox.showwarning(\"Warning\", \"No results to export.\")\n",
    "            return\n",
    "\n",
    "        file_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".xlsx\",\n",
    "            filetypes=[(\"Excel Files\", \"*.xlsx\")]\n",
    "        )\n",
    "\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "        wb = Workbook()\n",
    "\n",
    "        ws1 = wb.active\n",
    "        ws1.title = \"Record Comparison\"\n",
    "        ws1.append([\"Record\", \"Mitigation\", \"Prevention\", \"Resources\", \"Overall\"])\n",
    "\n",
    "        for r in self.comparison_results:\n",
    "            ws1.append([r[\"record\"], r[\"mitigation\"],\n",
    "                        r[\"prevention\"], r[\"resources\"], r[\"overall\"]])\n",
    "\n",
    "        ws2 = wb.create_sheet(\"Overall Averages\")\n",
    "        ws2.append([\"Section\", \"Average Similarity (%)\"])\n",
    "\n",
    "        for k,v in self.overall_averages.items():\n",
    "            ws2.append([k,v])\n",
    "\n",
    "        wb.save(file_path)\n",
    "        messagebox.showinfo(\"Success\", \"Excel report exported successfully!\")\n",
    "\n",
    "    # ---------------- Word Export ----------------\n",
    "\n",
    "    def export_word_report(self):\n",
    "\n",
    "        if not self.comparison_results:\n",
    "            messagebox.showwarning(\"Warning\", \"No results to export.\")\n",
    "            return\n",
    "\n",
    "        file_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".docx\",\n",
    "            filetypes=[(\"Word Documents\", \"*.docx\")]\n",
    "        )\n",
    "\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "        doc = Document()\n",
    "\n",
    "        doc.add_heading(\"Healthcare Breach Semantic Comparison Report\", level=0)\n",
    "        doc.add_paragraph(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        doc.add_paragraph(\"=\"*60)\n",
    "\n",
    "        doc.add_heading(\"Overall Similarity Summary\", level=1)\n",
    "        for section, value in self.overall_averages.items():\n",
    "            doc.add_paragraph(f\"{section}: {value}%\", style='List Bullet')\n",
    "\n",
    "        doc.add_page_break()\n",
    "\n",
    "        for record in self.comparison_results:\n",
    "\n",
    "            doc.add_heading(f\"Record {record['record']}\", level=1)\n",
    "\n",
    "            doc.add_paragraph(f\"Mitigation Similarity: {record['mitigation']}%\")\n",
    "            doc.add_paragraph(f\"Prevention Similarity: {record['prevention']}%\")\n",
    "            doc.add_paragraph(f\"Resources Similarity: {record['resources']}%\")\n",
    "            doc.add_paragraph(f\"Overall Similarity: {record['overall']}%\")\n",
    "\n",
    "            doc.add_heading(\"Mitigation Insight\", level=2)\n",
    "            doc.add_paragraph(record[\"mitigation_insight\"])\n",
    "\n",
    "            doc.add_heading(\"Prevention Insight\", level=2)\n",
    "            doc.add_paragraph(record[\"prevention_insight\"])\n",
    "\n",
    "            doc.add_heading(\"Resources Insight\", level=2)\n",
    "            doc.add_paragraph(record[\"resources_insight\"])\n",
    "\n",
    "            doc.add_page_break()\n",
    "\n",
    "        doc.save(file_path)\n",
    "        messagebox.showinfo(\"Success\", \"Word report exported successfully!\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Run App\n",
    "# ------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = BreachComparerApp()\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4fb6fcc-0e75-48e6-87cd-cfccca1990cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in d:\\python\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: sentence-transformers in d:\\python\\lib\\site-packages (5.2.2)\n",
      "Requirement already satisfied: ollama in d:\\python\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: lxml>=3.1.0 in d:\\python\\lib\\site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in d:\\python\\lib\\site-packages (from python-docx) (4.15.0)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in d:\\python\\lib\\site-packages (from sentence-transformers) (5.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\python\\lib\\site-packages (from sentence-transformers) (1.3.7)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\python\\lib\\site-packages (from sentence-transformers) (2.10.0)\n",
      "Requirement already satisfied: numpy in d:\\python\\lib\\site-packages (from sentence-transformers) (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in d:\\python\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in d:\\python\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: tqdm in d:\\python\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: filelock in d:\\python\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\python\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\python\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\python\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.9.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in d:\\python\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in d:\\python\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\python\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\python\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in d:\\python\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\python\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in d:\\python\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
      "Requirement already satisfied: anyio in d:\\python\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: certifi in d:\\python\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\python\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\python\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in d:\\python\\lib\\site-packages (from ollama) (2.12.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\python\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\python\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\python\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\python\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\python\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\python\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\python\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\python\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\python\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\python\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\python\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\python\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\python\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\python\\lib\\site-packages (from typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (8.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx sentence-transformers ollama openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f71313-e3ce-455b-861a-b172a48ae299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on bash ollama pull llama3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
